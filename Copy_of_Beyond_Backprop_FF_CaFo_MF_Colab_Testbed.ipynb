{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surfingtheuniverse/Colab-Mono-Forward/blob/main/Copy_of_Beyond_Backprop_FF_CaFo_MF_Colab_Testbed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y5NpS8T5l_S"
      },
      "source": [
        "# Beyond Backprop: FF, CaFo, MF — Colab Testbed\n",
        "\n",
        "This notebook implements and **tests three BP-free algorithms** from the paper:\n",
        "\n",
        "- **Forward-Forward (FF)** (Hinton)\n",
        "- **Cascaded-Forward (CaFo)** (Zhao et al.)\n",
        "- **Mono-Forward (MF)** (Gong, Li, Abdulla)\n",
        "\n",
        "…alongside **fair backpropagation (BP) baselines** on identical architectures.\n",
        "\n",
        "**Datasets supported:** MNIST, Fashion-MNIST, CIFAR-10 (pick in the Config cell). Defaults are chosen for fast demo runs on Colab.\n",
        "\n",
        "**Notes**\n",
        "- Training defaults are small for speed. Increase epochs/batch size later for stronger results.\n",
        "- Optional GPU **energy tracking** via NVML is enabled when possible.\n",
        "- Each algorithm follows its **native architecture** described in the paper.\n",
        "- All methods use **early stopping** on a validation split.\n",
        "\n",
        "If you run into CUDA OOM on Colab, switch to a smaller model or smaller batch size in the Config cell.\n"
      ],
      "id": "-Y5NpS8T5l_S"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_sqHlse5l_V",
        "outputId": "b3679b08-bbc2-47ab-fe6b-011dcd190d55"
      },
      "source": [
        "#@title Setup\n",
        "import os, math, random, time\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "\n",
        "try:\n",
        "    import pynvml\n",
        "    _HAS_NVML = True\n",
        "except Exception:\n",
        "    _HAS_NVML = False\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Torch:', torch.__version__, 'CUDA:', torch.cuda.is_available(), 'Device:', DEVICE)\n"
      ],
      "id": "X_sqHlse5l_V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch: 2.8.0+cu126 CUDA: True Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omGL7qOX5l_V",
        "outputId": "215d62a1-f523-4982-fbc4-939984c7d080"
      },
      "source": [
        "#@title Config\n",
        "dataset = 'FashionMNIST'  #@param ['MNIST','FashionMNIST','CIFAR10']\n",
        "algo_to_run = 'ALL'        #@param ['ALL','FF','CaFo','MF','BP']\n",
        "batch_size = 128           #@param {type:'integer'}\n",
        "max_epochs = 5             #@param {type:'integer'}\n",
        "patience = 2               #@param {type:'integer'}\n",
        "lr_bp = 3e-4               #@param {type:'number'}\n",
        "lr_ff = 3e-4               #@param {type:'number'}\n",
        "lr_mf = 3e-4               #@param {type:'number'}\n",
        "lr_cafo_pred = 3e-4        #@param {type:'number'}\n",
        "use_energy_tracking = True #@param {type:'boolean'}\n",
        "\n",
        "print(f'Config: dataset={dataset}, algo={algo_to_run}, bs={batch_size}, epochs={max_epochs}')\n"
      ],
      "id": "omGL7qOX5l_V",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Config: dataset=FashionMNIST, algo=ALL, bs=128, epochs=5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4fnlFX25l_V"
      },
      "source": [
        "#@title Utilities: EarlyStopping + Energy Meter\n",
        "class EarlyStopper:\n",
        "    def __init__(self, patience=3, mode='max'):\n",
        "        self.patience = patience\n",
        "        self.mode = mode\n",
        "        self.best = -1e18 if mode=='max' else 1e18\n",
        "        self.count = 0\n",
        "        self.stop = False\n",
        "        self.best_state = None\n",
        "\n",
        "    def step(self, value, model):\n",
        "        improved = (value > self.best) if self.mode=='max' else (value < self.best)\n",
        "        if improved:\n",
        "            self.best = value\n",
        "            self.count = 0\n",
        "            self.best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
        "        else:\n",
        "            self.count += 1\n",
        "            if self.count >= self.patience:\n",
        "                self.stop = True\n",
        "\n",
        "class EnergyMeter:\n",
        "    def __init__(self, enable=True):\n",
        "        self.enable = enable and _HAS_NVML and torch.cuda.is_available()\n",
        "        self.energy_joules = 0.0\n",
        "        self._last_t = None\n",
        "        self._last_w = None\n",
        "        if self.enable:\n",
        "            try:\n",
        "                pynvml.nvmlInit()\n",
        "                self.handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "                self._last_t = time.time()\n",
        "                self._last_w = pynvml.nvmlDeviceGetPowerUsage(self.handle)  # milliwatts\n",
        "            except Exception:\n",
        "                self.enable = False\n",
        "\n",
        "    def tick(self):\n",
        "        if not self.enable:\n",
        "            return\n",
        "        t = time.time()\n",
        "        try:\n",
        "            w_mw = pynvml.nvmlDeviceGetPowerUsage(self.handle) # milliwatts\n",
        "        except Exception:\n",
        "            return\n",
        "        if self._last_t is not None:\n",
        "            dt = t - self._last_t\n",
        "            # integrate trapezoidally (mW to W is /1000)\n",
        "            self.energy_joules += dt * ( (self._last_w + w_mw) * 0.5 / 1000.0 )\n",
        "        self._last_t, self._last_w = t, w_mw\n",
        "\n",
        "    def wh(self):\n",
        "        # Joules to Wh: 1 Wh = 3600 J\n",
        "        return self.energy_joules / 3600.0\n"
      ],
      "id": "h4fnlFX25l_V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBZStB3a5l_W",
        "outputId": "ec585167-ef86-489c-8b11-985b179f2e8f"
      },
      "source": [
        "#@title Data: Loaders + Normalization\n",
        "def get_data(dataset: str, batch_size: int):\n",
        "    if dataset in ['MNIST','FashionMNIST']:\n",
        "        mean, std = ((0.1307,), (0.3081,)) if dataset=='MNIST' else ((0.2860,), (0.3530,))\n",
        "        tfm = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n",
        "        ds_cls = torchvision.datasets.MNIST if dataset=='MNIST' else torchvision.datasets.FashionMNIST\n",
        "        train = ds_cls(root='./data', train=True, download=True, transform=tfm)\n",
        "        test  = ds_cls(root='./data', train=False, download=True, transform=tfm)\n",
        "        n_val = int(0.1 * len(train))\n",
        "        n_tr  = len(train) - n_val\n",
        "        train, val = random_split(train, [n_tr, n_val])\n",
        "        in_ch, ncls, img_hw = 1, 10, 28\n",
        "    elif dataset=='CIFAR10':\n",
        "        tfm_train = T.Compose([\n",
        "            T.RandomCrop(32, padding=4),\n",
        "            T.RandomHorizontalFlip(),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
        "        ])\n",
        "        tfm_test = T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
        "        ])\n",
        "        train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=tfm_train)\n",
        "        test  = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=tfm_test)\n",
        "        n_val = int(0.1 * len(train))\n",
        "        n_tr  = len(train) - n_val\n",
        "        train, val = random_split(train, [n_tr, n_val])\n",
        "        in_ch, ncls, img_hw = 3, 10, 32\n",
        "    else:\n",
        "        raise ValueError('Unsupported dataset')\n",
        "\n",
        "    dl_train = DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    dl_val   = DataLoader(val, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    dl_test  = DataLoader(test, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    return dl_train, dl_val, dl_test, in_ch, ncls, img_hw\n",
        "\n",
        "dl_train, dl_val, dl_test, IN_CH, NCLS, IMG = get_data(dataset, batch_size)\n",
        "IN_CH, NCLS, IMG\n"
      ],
      "id": "KBZStB3a5l_W",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:02<00:00, 10.3MB/s]\n",
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 176kB/s]\n",
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.30MB/s]\n",
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 14.4MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3kq4oc95l_W"
      },
      "source": [
        "#@title Models: BP baselines (MLP + CNN)\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim, ncls, hidden: List[int]):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        last = in_dim\n",
        "        for h in hidden:\n",
        "            layers += [nn.Linear(last, h), nn.ReLU(inplace=True)]\n",
        "            last = h\n",
        "        self.backbone = nn.Sequential(*layers)\n",
        "        self.head = nn.Linear(last, ncls)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        z = self.backbone(x)\n",
        "        return self.head(z)\n",
        "\n",
        "class SimpleCNN3(nn.Module):\n",
        "    # Matches CaFo native 3-block CNN shape (Conv3x3->ReLU->MaxPool2x2->BN) x3\n",
        "    def __init__(self, in_ch=1, ncls=10, chans=(32,128,512)):\n",
        "        super().__init__()\n",
        "        c1,c2,c3 = chans\n",
        "        self.b1 = nn.Sequential(nn.Conv2d(in_ch,c1,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c1))\n",
        "        self.b2 = nn.Sequential(nn.Conv2d(c1,c2,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c2))\n",
        "        self.b3 = nn.Sequential(nn.Conv2d(c2,c3,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c3))\n",
        "        self.head = None  # will init after seeing input size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.b1(x); x = self.b2(x); x = self.b3(x)\n",
        "        if self.head is None:\n",
        "            flat = x.view(x.size(0), -1)\n",
        "            self.head = nn.Linear(flat.size(1), NCLS).to(x.device)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.head(x)\n"
      ],
      "id": "L3kq4oc95l_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQTIfdjq5l_W"
      },
      "source": [
        "#@title Algorithm 1: Forward-Forward (FF) — MLP\n",
        "class FFMLP(nn.Module):\n",
        "    def __init__(self, in_dim, layers: List[int]):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([nn.Linear(a, b) for a,b in zip([in_dim]+layers[:-1], layers)])\n",
        "\n",
        "    @staticmethod\n",
        "    def length_norm(x, eps=1e-8):\n",
        "        # normalize each sample vector to unit L2\n",
        "        return x / (x.norm(dim=1, keepdim=True) + eps)\n",
        "\n",
        "    def forward_feats(self, x):\n",
        "        acts = []\n",
        "        for L in self.layers:\n",
        "            x = F.relu(L(x))\n",
        "            acts.append(x)\n",
        "            x = self.length_norm(x)\n",
        "        return acts  # list of layer activations (post-ReLU, pre-length-norm next step)\n",
        "\n",
        "def embed_label(x, y, ncls=10, img_hw=28):\n",
        "    # Replace first ncls pixels with one-hot label (as in Hinton's demo)\n",
        "    b = x.size(0)\n",
        "    flat = x.view(b, -1)\n",
        "    oh = torch.zeros(b, ncls, device=x.device)\n",
        "    oh[torch.arange(b), y] = 1.0\n",
        "    flat[:, :ncls] = oh\n",
        "    return flat\n",
        "\n",
        "def ff_goodness(a):\n",
        "    return (a*a).sum(dim=1)\n",
        "\n",
        "def train_ff(ff: FFMLP, dl_train, dl_val, in_dim, ncls, img_hw, max_epochs=5, lr=3e-4, patience=2):\n",
        "    ff = ff.to(DEVICE)\n",
        "    opt = torch.optim.AdamW(ff.parameters(), lr=lr)\n",
        "    stopper = EarlyStopper(patience=patience, mode='max')\n",
        "    energy = EnergyMeter(enable=use_energy_tracking)\n",
        "\n",
        "    def epoch_pass(dloader, train=True):\n",
        "        if train: ff.train()\n",
        "        else: ff.eval()\n",
        "        tot, correct = 0, 0\n",
        "        for x,y in dloader:\n",
        "            energy.tick()\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            # Build positive and negative batches\n",
        "            pos = embed_label(x.clone(), y, ncls=ncls, img_hw=img_hw)\n",
        "            neg_labels = (y + torch.randint_like(y, low=1, high=ncls)) % ncls\n",
        "            neg = embed_label(x.clone(), neg_labels, ncls=ncls, img_hw=img_hw)\n",
        "            # Forward acts for pos/neg\n",
        "            acts_pos = ff.forward_feats(pos.view(pos.size(0), -1))\n",
        "            acts_neg = ff.forward_feats(neg.view(neg.size(0), -1))\n",
        "            # Logistic loss per layer on goodness diff\n",
        "            losses = []\n",
        "            for ap, an in zip(acts_pos, acts_neg):\n",
        "                gp, gn = ff_goodness(ap), ff_goodness(an)\n",
        "                # threshold ~ layer width; encourages separation\n",
        "                thresh = ap.size(1)\n",
        "                # pos should be > thresh; neg should be < thresh\n",
        "                loss = F.softplus(-(gp - thresh)).mean() + F.softplus((gn - thresh)).mean()\n",
        "                losses.append(loss)\n",
        "            loss = torch.stack(losses).mean()\n",
        "            if train:\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "\n",
        "            # Inference: try each label, pick max total goodness\n",
        "            with torch.no_grad():\n",
        "                b = x.size(0)\n",
        "                scores = torch.zeros(b, ncls, device=DEVICE)\n",
        "                flat = x.view(b,-1)\n",
        "                for c in range(ncls):\n",
        "                    tmp = embed_label(flat.clone(), torch.full_like(y, c), ncls=ncls, img_hw=img_hw)\n",
        "                    acts = ff.forward_feats(tmp)\n",
        "                    scores[:, c] = torch.stack([ff_goodness(a) for a in acts], dim=0).sum(dim=0)\n",
        "                pred = scores.argmax(dim=1)\n",
        "                correct += (pred==y).sum().item(); tot += b\n",
        "        return correct/tot, energy.wh()\n",
        "\n",
        "    best_wh = 0.0\n",
        "    for ep in range(1, max_epochs+1):\n",
        "        tr_acc, _ = epoch_pass(dl_train, train=True)\n",
        "        val_acc, wh = epoch_pass(dl_val, train=False)\n",
        "        print(f'[FF] epoch {ep:02d}  train_acc={tr_acc:.3f}  val_acc={val_acc:.3f}  energy_Wh~{wh:.3f}')\n",
        "        stopper.step(val_acc, ff)\n",
        "        best_wh = wh\n",
        "        if stopper.stop:\n",
        "            print('[FF] Early stop!')\n",
        "            break\n",
        "    if stopper.best_state:\n",
        "        ff.load_state_dict(stopper.best_state)\n",
        "    return ff\n",
        "\n",
        "def test_model(model, dl):\n",
        "    model.eval(); tot=0; corr=0\n",
        "    with torch.no_grad():\n",
        "        for x,y in dl:\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            logits = model(x)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            corr += (pred==y).sum().item(); tot += x.size(0)\n",
        "    return corr/tot\n"
      ],
      "id": "vQTIfdjq5l_W",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyF2IwBJ5l_X"
      },
      "source": [
        "#@title Algorithm 2: CaFo (Rand-CE variant) — CNN with 3 block predictors\n",
        "class CaFoPredictor(nn.Module):\n",
        "    def __init__(self, in_dim, ncls):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, ncls)\n",
        "    def forward(self, x):\n",
        "        return self.fc(x)\n",
        "\n",
        "class CaFoBackbone(nn.Module):\n",
        "    def __init__(self, in_ch=1, chans=(32,128,512)):\n",
        "        super().__init__()\n",
        "        c1,c2,c3 = chans\n",
        "        self.b1 = nn.Sequential(nn.Conv2d(in_ch,c1,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c1))\n",
        "        self.b2 = nn.Sequential(nn.Conv2d(c1,c2,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c2))\n",
        "        self.b3 = nn.Sequential(nn.Conv2d(c2,c3,3,padding=1), nn.ReLU(True), nn.MaxPool2d(2), nn.BatchNorm2d(c3))\n",
        "        for p in self.parameters():\n",
        "            p.requires_grad_(False)  # Rand-CE keeps blocks frozen\n",
        "\n",
        "    def forward_blocks(self, x):\n",
        "        f1 = self.b1(x)\n",
        "        f2 = self.b2(f1)\n",
        "        f3 = self.b3(f2)\n",
        "        return f1, f2, f3\n",
        "\n",
        "def train_cafo_rand(dl_train, dl_val, in_ch, ncls, max_epochs=5, lr=3e-4, patience=2, chans=(32,128,512)):\n",
        "    bb = CaFoBackbone(in_ch=in_ch, chans=chans).to(DEVICE)\n",
        "    # Run one batch to infer dims\n",
        "    xb, yb = next(iter(dl_train))\n",
        "    xb = xb.to(DEVICE)\n",
        "    f1,f2,f3 = bb.forward_blocks(xb)\n",
        "    p1 = CaFoPredictor(f1.view(f1.size(0), -1).size(1), ncls).to(DEVICE)\n",
        "    p2 = CaFoPredictor(f2.view(f2.size(0), -1).size(1), ncls).to(DEVICE)\n",
        "    p3 = CaFoPredictor(f3.view(f3.size(0), -1).size(1), ncls).to(DEVICE)\n",
        "    preds = [p1,p2,p3]\n",
        "    opts  = [torch.optim.Adam(p.parameters(), lr=lr) for p in preds]\n",
        "    stoppers = [EarlyStopper(patience=patience, mode='max') for _ in preds]\n",
        "    energy = EnergyMeter(enable=use_energy_tracking)\n",
        "\n",
        "    def train_one_predictor(idx):\n",
        "        P = preds[idx]; Opt = opts[idx]; Stop = stoppers[idx]\n",
        "        for ep in range(1, max_epochs+1):\n",
        "            P.train();\n",
        "            for x,y in dl_train:\n",
        "                energy.tick()\n",
        "                x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "                with torch.no_grad():\n",
        "                    feats = bb.forward_blocks(x)[idx]\n",
        "                feats = feats.view(feats.size(0), -1)\n",
        "                logits = P(feats)\n",
        "                loss = F.cross_entropy(logits, y)\n",
        "                Opt.zero_grad(); loss.backward(); Opt.step()\n",
        "            # val\n",
        "            P.eval(); correct=0; tot=0\n",
        "            with torch.no_grad():\n",
        "                for x,y in dl_val:\n",
        "                    x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "                    feats = bb.forward_blocks(x)[idx]\n",
        "                    feats = feats.view(feats.size(0), -1)\n",
        "                    logits = P(feats)\n",
        "                    pred = logits.argmax(dim=1)\n",
        "                    correct += (pred==y).sum().item(); tot += x.size(0)\n",
        "            val_acc = correct/tot\n",
        "            print(f'[CaFo-P{idx+1}] epoch {ep:02d} val_acc={val_acc:.3f}')\n",
        "            Stop.step(val_acc, P)\n",
        "            if Stop.stop:\n",
        "                print(f'[CaFo-P{idx+1}] Early stop!')\n",
        "                break\n",
        "        if Stop.best_state:\n",
        "            preds[idx].load_state_dict(Stop.best_state)\n",
        "\n",
        "    for i in range(3):\n",
        "        train_one_predictor(i)\n",
        "    return bb, preds\n",
        "\n",
        "def cafo_infer(bb, preds, dl):\n",
        "    for p in preds: p.eval()\n",
        "    bb.eval(); correct=0; tot=0\n",
        "    with torch.no_grad():\n",
        "        for x,y in dl:\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            f1,f2,f3 = bb.forward_blocks(x)\n",
        "            logits = 0\n",
        "            for feats,P in zip([f1,f2,f3], preds):\n",
        "                feats = feats.view(feats.size(0), -1)\n",
        "                logits = logits + P(feats)\n",
        "            pred = logits.argmax(dim=1)\n",
        "            correct += (pred==y).sum().item(); tot += x.size(0)\n",
        "    return correct/tot\n"
      ],
      "id": "CyF2IwBJ5l_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjB59fcG5l_X"
      },
      "source": [
        "#@title Algorithm 3: Mono-Forward (MF) — MLP with projection matrices per hidden layer\n",
        "class MFBlock(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, ncls):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(in_dim, out_dim)\n",
        "        self.ncls = ncls\n",
        "        self.M = nn.Linear(out_dim, ncls, bias=False)  # projects activations -> class scores\n",
        "\n",
        "    def forward(self, x):\n",
        "        a = F.relu(self.fc(x))\n",
        "        g = self.M(a)  # goodness scores per class\n",
        "        return a, g\n",
        "\n",
        "class MFNet(nn.Module):\n",
        "    def __init__(self, in_dim, ncls, layers: List[int]):\n",
        "        super().__init__()\n",
        "        dims = [in_dim] + layers\n",
        "        self.blocks = nn.ModuleList([MFBlock(dims[i], dims[i+1], ncls) for i in range(len(layers))])\n",
        "        self.ncls = ncls\n",
        "\n",
        "    def forward_all(self, x):\n",
        "        # Ensure inputs are flattened for MLP use, regardless of caller\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1)\n",
        "        acts, scores = [], []\n",
        "        for b in self.blocks:\n",
        "            x, g = b(x)\n",
        "            acts.append(x); scores.append(g)\n",
        "        return acts, scores\n",
        "\n",
        "    def forward(self, x):\n",
        "        # BP-style inference: only final layer's scores\n",
        "        if x.dim() > 2:\n",
        "            x = x.view(x.size(0), -1)\n",
        "        _, scores = self.forward_all(x)\n",
        "        return scores[-1]\n",
        "\n",
        "def train_mf(mf: MFNet, dl_train, dl_val, in_dim, max_epochs=5, lr=3e-4, patience=2):\n",
        "    mf = mf.to(DEVICE)\n",
        "    opt = torch.optim.Adam([p for p in mf.parameters()], lr=lr)\n",
        "    stopper = EarlyStopper(patience=patience, mode='max')\n",
        "    energy = EnergyMeter(enable=use_energy_tracking)\n",
        "\n",
        "    def run_epoch(dloader, train=True):\n",
        "        if train: mf.train()\n",
        "        else: mf.eval()\n",
        "        tot, corr = 0, 0\n",
        "        for x,y in dloader:\n",
        "            energy.tick()\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            acts, scores = mf.forward_all(x)  # now handles flatten internally\n",
        "            # local CE loss on each layer's scores\n",
        "            losses = [F.cross_entropy(g, y) for g in scores]\n",
        "            loss = torch.stack(losses).mean()\n",
        "            if train:\n",
        "                opt.zero_grad(); loss.backward(); opt.step()\n",
        "            with torch.no_grad():\n",
        "                pred = scores[-1].argmax(dim=1)\n",
        "                corr += (pred==y).sum().item(); tot += x.size(0)\n",
        "        return corr/tot, energy.wh()\n",
        "\n",
        "    for ep in range(1, max_epochs+1):\n",
        "        tr_acc, _ = run_epoch(dl_train, train=True)\n",
        "        val_acc, wh = run_epoch(dl_val, train=False)\n",
        "        print(f'[MF] epoch {ep:02d}  train_acc={tr_acc:.3f}  val_acc={val_acc:.3f}  energy_Wh~{wh:.3f}')\n",
        "        stopper.step(val_acc, mf)\n",
        "        if stopper.stop:\n",
        "            print('[MF] Early stop!')\n",
        "            break\n",
        "    if stopper.best_state:\n",
        "        mf.load_state_dict(stopper.best_state)\n",
        "    return mf\n"
      ],
      "id": "ZjB59fcG5l_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2eLU4fG5l_X",
        "outputId": "6f6fe589-deac-4b39-c55f-35214dc731e1"
      },
      "source": [
        "#@title Train & Evaluate Selected Algorithm(s)\n",
        "in_dim = IN_CH * IMG * IMG\n",
        "results = {}\n",
        "\n",
        "if algo_to_run in ['BP','ALL']:\n",
        "    print('== BP baseline ==')\n",
        "    if dataset in ['MNIST','FashionMNIST']:\n",
        "        # MF native: 2x1000 for MNIST/FashionMNIST\n",
        "        model = MLP(in_dim, NCLS, hidden=[1000,1000]).to(DEVICE)\n",
        "    else:\n",
        "        # CaFo native: 3-block CNN\n",
        "        model = SimpleCNN3(IN_CH, NCLS).to(DEVICE)\n",
        "    opt = torch.optim.AdamW(model.parameters(), lr=lr_bp)\n",
        "    stopper = EarlyStopper(patience=patience, mode='max')\n",
        "    energy = EnergyMeter(enable=use_energy_tracking)\n",
        "    for ep in range(1, max_epochs+1):\n",
        "        model.train()\n",
        "        for x,y in dl_train:\n",
        "            energy.tick()\n",
        "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "            opt.zero_grad(); loss.backward(); opt.step()\n",
        "        val_acc = test_model(model, dl_val)\n",
        "        print(f'[BP] epoch {ep:02d} val_acc={val_acc:.3f}')\n",
        "        stopper.step(val_acc, model)\n",
        "        if stopper.stop:\n",
        "            print('[BP] Early stop!')\n",
        "            break\n",
        "    if stopper.best_state:\n",
        "        model.load_state_dict(stopper.best_state)\n",
        "    test_acc = test_model(model, dl_test)\n",
        "    results['BP'] = test_acc\n",
        "    print('BP test_acc =', test_acc)\n",
        "\n",
        "if algo_to_run in ['FF','ALL'] and dataset in ['MNIST','FashionMNIST','CIFAR10']:\n",
        "    print('\\n== Forward-Forward ==')\n",
        "    # FF native: MLP; 4x2000 for FashionMNIST per paper; for Colab speed we use 3x1000 by default\n",
        "    layers = [1000,1000,1000] if dataset!='FashionMNIST' else [2000,2000]  # tweak for speed/oom\n",
        "    ff = FFMLP(in_dim, layers)\n",
        "    ff = train_ff(ff, dl_train, dl_val, in_dim, NCLS, IMG, max_epochs=max_epochs, lr=lr_ff, patience=patience)\n",
        "    # FF inference wrapper for uniform test\n",
        "    class FFWrapper(nn.Module):\n",
        "        def __init__(self, ff):\n",
        "            super().__init__(); self.ff=ff\n",
        "        def forward(self, x):\n",
        "            b = x.size(0)\n",
        "            scores = torch.zeros(b, NCLS, device=x.device)\n",
        "            flat = x.view(b,-1)\n",
        "            for c in range(NCLS):\n",
        "                tmp = embed_label(flat.clone(), torch.full((b,), c, device=x.device, dtype=torch.long), ncls=NCLS, img_hw=IMG)\n",
        "                acts = self.ff.forward_feats(tmp)\n",
        "                scores[:, c] = torch.stack([ff_goodness(a) for a in acts], dim=0).sum(dim=0)\n",
        "            return scores\n",
        "    test_acc = test_model(FFWrapper(ff).to(DEVICE), dl_test)\n",
        "    results['FF'] = test_acc\n",
        "    print('FF test_acc =', test_acc)\n",
        "\n",
        "if algo_to_run in ['CaFo','ALL']:\n",
        "    print('\\n== CaFo (Rand-CE) ==')\n",
        "    # Native CNN 3 blocks; predictors trained independently, blocks frozen\n",
        "    chans = (32,128,512) if dataset!='CIFAR10' else (32,128,256)  # lighter for CIFAR10 on Colab\n",
        "    bb, preds = train_cafo_rand(dl_train, dl_val, IN_CH, NCLS, max_epochs=max_epochs, lr=lr_cafo_pred, patience=patience, chans=chans)\n",
        "    test_acc = cafo_infer(bb, preds, dl_test)\n",
        "    results['CaFo'] = test_acc\n",
        "    print('CaFo test_acc =', test_acc)\n",
        "\n",
        "if algo_to_run in ['MF','ALL'] and dataset in ['MNIST','FashionMNIST','CIFAR10']:\n",
        "    print('\\n== Mono-Forward ==')\n",
        "    # Native MLP: 2x1000 for MNIST/FashionMNIST, 3x2000 for CIFAR10 (downsized for Colab)\n",
        "    layers = [1000,1000] if dataset in ['MNIST','FashionMNIST'] else [1024,1024]\n",
        "    mf = MFNet(in_dim, NCLS, layers)\n",
        "    mf = train_mf(mf, dl_train, dl_val, in_dim, max_epochs=max_epochs, lr=lr_mf, patience=patience)\n",
        "    test_acc = test_model(mf.to(DEVICE), dl_test)\n",
        "    results['MF'] = test_acc\n",
        "    print('MF test_acc =', test_acc)\n",
        "\n",
        "print('\\nSummary:', results)\n"
      ],
      "id": "w2eLU4fG5l_X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== BP baseline ==\n",
            "[BP] epoch 01 val_acc=0.860\n",
            "[BP] epoch 02 val_acc=0.876\n",
            "[BP] epoch 03 val_acc=0.877\n",
            "[BP] epoch 04 val_acc=0.881\n",
            "[BP] epoch 05 val_acc=0.886\n",
            "BP test_acc = 0.8736\n",
            "\n",
            "== Forward-Forward ==\n",
            "[FF] epoch 01  train_acc=0.400  val_acc=0.620  energy_Wh~0.172\n",
            "[FF] epoch 02  train_acc=0.667  val_acc=0.662  energy_Wh~0.357\n",
            "[FF] epoch 03  train_acc=0.724  val_acc=0.724  energy_Wh~0.532\n",
            "[FF] epoch 04  train_acc=0.749  val_acc=0.763  energy_Wh~0.706\n",
            "[FF] epoch 05  train_acc=0.771  val_acc=0.769  energy_Wh~0.884\n",
            "FF test_acc = 0.7596\n",
            "\n",
            "== CaFo (Rand-CE) ==\n",
            "[CaFo-P1] epoch 01 val_acc=0.877\n",
            "[CaFo-P1] epoch 02 val_acc=0.886\n",
            "[CaFo-P1] epoch 03 val_acc=0.891\n",
            "[CaFo-P1] epoch 04 val_acc=0.893\n",
            "[CaFo-P1] epoch 05 val_acc=0.893\n",
            "[CaFo-P2] epoch 01 val_acc=0.884\n",
            "[CaFo-P2] epoch 02 val_acc=0.890\n",
            "[CaFo-P2] epoch 03 val_acc=0.899\n",
            "[CaFo-P2] epoch 04 val_acc=0.902\n",
            "[CaFo-P2] epoch 05 val_acc=0.907\n",
            "[CaFo-P3] epoch 01 val_acc=0.882\n",
            "[CaFo-P3] epoch 02 val_acc=0.887\n",
            "[CaFo-P3] epoch 03 val_acc=0.892\n",
            "[CaFo-P3] epoch 04 val_acc=0.900\n",
            "[CaFo-P3] epoch 05 val_acc=0.897\n",
            "CaFo test_acc = 0.9066\n",
            "\n",
            "== Mono-Forward ==\n",
            "[MF] epoch 01  train_acc=0.818  val_acc=0.861  energy_Wh~0.102\n",
            "[MF] epoch 02  train_acc=0.871  val_acc=0.874  energy_Wh~0.202\n",
            "[MF] epoch 03  train_acc=0.885  val_acc=0.882  energy_Wh~0.302\n",
            "[MF] epoch 04  train_acc=0.893  val_acc=0.870  energy_Wh~0.402\n",
            "[MF] epoch 05  train_acc=0.903  val_acc=0.890  energy_Wh~0.501\n",
            "MF test_acc = 0.8807\n",
            "\n",
            "Summary: {'BP': 0.8736, 'FF': 0.7596, 'CaFo': 0.9066, 'MF': 0.8807}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzbPBBDH5l_X"
      },
      "source": [
        "## What to tweak next\n",
        "- Increase `max_epochs`, `batch_size`, and model width for stronger results.\n",
        "- Switch dataset to `CIFAR10` for a harder benchmark.\n",
        "- Enable a Colab GPU (Runtime → Change runtime type → T4/L4/A100), and keep `use_energy_tracking=True` to log approximate GPU energy.\n",
        "- For CaFo-DFA or Optuna tuning, extend the notebook (this demo uses CaFo Rand-CE for simplicity and runtime).\n"
      ],
      "id": "uzbPBBDH5l_X"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}